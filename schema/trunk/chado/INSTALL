                            CHADO INSTALLATION
 
$Id: INSTALL,v 1.40 2005-05-02 16:13:09 scottcain Exp $

This document describes the procedure for installing the chado 
schema and loading data from GFF3 data records.  This is currently
considered alpha software, so expect there to be bumps in the road.  When
you experience problems, please email them to the gmod-devel mailing list
at gmod-devel@lists.sourceforge.net.  This release will work with the
most recent release of the Generic Genome Browser (gbrowse) version 1.62
though there have been bug fixes to gbrowse that will be rolled into
a new 1.63 release in the near future.  If you experience difficulties
with gbrowse and chado, you might want to look at getting a cvs
checkout of the bugfix branch.  The installation instructions for
gbrowse are included in that package.  There are plans to make the
installation of gbrowse and other components more automatic, but for
the time being, please unpack it and install separately.

This release of chado/gmod also comes with example functions for
allowing Apollo (http://www.gmod.org/apollo.shtml) to read and
write directly to the database, allowing creation and editing of
genome features.  Please see the file README.Apollo for some details
on setting this up.

Thanks,
Scott Cain
cain@cshl.edu
May 2, 2005

Prerequisites:

  PostgreSQL (currently, developers are using 7.4). Items to do with
  postgres to make it ready to go:

    * make it accept tcp/ip connections by adding this line to postgresql.conf
      (must be done either as user root or postgres; database must be restarted
      in order for this change to take affect):

        tcpip_socket = true

    * create a database user with permission to drop and add databases;
      the database user name should be the same as your unix user name to
      allow the software build to progress smoothly (must be done as user
      postgres; createuser is a commandline program that comes with the
      PostgreSQL package):
        
        # createuser --createdb <your username> 

    * tell postgres that it can use the plpgsql language (as user
      postgres; createlang is a commandline program that comes with
      the PostgreSQL package):

        # createlang plpgsql template1

    * edit the pg_hba.conf (either as the user 'root' or 'postgres') to give
      the user created above permission to access the database.  Read
      the comments in pg_hba.conf regarding permissions.  My pg_hba.conf looks
      like this (which is very loose permissions):

# TYPE  DATABASE    USER        IP-ADDRESS        IP-MASK           METHOD
                                                                                
local   all         all                                             trust
host    all         all         127.0.0.1         255.255.255.255   trust


    * for information on tuning postgres for performance, see

         http://www.varlena.com/varlena/GeneralBits/Tidbits/perf.html

      the two most critical parameters to tune are shared_buffers and
      effective_cache size.  Adjusting these parameters may require
      modification of memory settings in /etc/sysctl.conf, see the sysctl
      manpage for details.  Also critical for continued performance of
      postgres is the regular execution of the VACUUM FULL ANALYZE command.
      This command clears out old, deleted data and analyzes the structure
      of the database so that the execution planner can predict the
      fastest way to execute a given query.

      While the above link describes tuning in general, the examples given
      for tuning kernel parameters are Linux specific.  For setting 
      shmmax on Mac OS X boxes, edit 

          /System/Library/StartupItems/SystemTuning/SystemTuning (for OS X 10.2)
        
      or
 
          /etc/rc (for OS X 10.3)

      to increase the values of shmmax and shmall, like this:

          sysctl -w kern.sysv.shmmax=52428800 # bytes: 50 megs
          sysctl -w kern.sysv.shmmin=1
          sysctl -w kern.sysv.shmmni=32
          sysctl -w kern.sysv.shmseg=8
          sysctl -w kern.sysv.shmall=25600 # 4k pages: 100 megs

      (these are the values I use for my Mac that has 1.2 G RAM) and reboot.

      For my linux box with 512M RAM, I use these values in /etc/sysctl.conf:

         kernel.shmall = 134217728
         kernel.shmmax = 134217728

      and make these changes to the postgresql.conf file:

         tcpip_socket = true
         sort_mem=2048
         max_connections = 32


  Apache (1.3.* or 2.0.*) (for gbrowse, gmod-web requires 2.0)

  BioPerl (bioperl-live or greater than 1.5)
          (-microarray 0.1 --required for microarray data)

  Standard Perl modules:
      The perl modules can be installed via the cpan shell and by issuing 
      the command 'install Bundle::GMOD' which will install all of the 
      modules below except for SQL::Translator, which is optional.

    * CGI                      (GBrowse)
    * GD                       (GBrowse)
    * DBI                      (GBrowse,chado)
    * DBD::Pg                  (GBrowse,chado)
    * SQL::Translator (0.05 or cvs) (chado) (optional)
    * Digest::MD5              (GBrowse)
    * Text::Shellwords         (GBrowse)
    * Module::Build            (chado)
    * Class::DBI               (chado)
    * Class::DBI::Pg           (chado)
    * Class::DBI::Pager        (chado)
    * XML::Simple              (chado)
    * LWP                      (chado)
    * Template                 (chado)
    * Log::Log4perl            (chado)
    * Term::ProgressBar (2.06 or better)  (chado)
  

This document describes how to install the Chado schema:

1.  First, you must should set the following variables in your environment.
    If you are using bash or a bash-like shell, this is done via a command
    like this:

       $ export VARNAME=value

    If you are using a csh-like shell, it is done like this:

       $ setenv VARNAME value

   * GMOD_ROOT: The location of your GMOD installation (e.g., "/usr/local/gmod")

   * CHADO_DB_NAME: The name of your Chado database

   * CHADO_DB_USERNAME: The username to connect to Chado

   * CHADO_DB_PASSWORD: The password for the database user [opt]

   * CHADO_DB_HOST: The host on which the database runs (e.g. "localhost") [opt]

   * CHADO_DB_PORT: The port on which the database is listening [opt]

As indicated, the host, port, and password are optional.

*   Note: a mechanism exists to pass these variables directly to the
    installer during the "perl Makefile.PL" step.  By giving key=value pairs,
    it is possible to avoid setting environmental variables.  The syntax is as:

       perl Makefile.PL GMOD_ROOT=/usr/local/gmod CHADO_DB_NAME=dev_chado_01

    Backward compatibility may not be maintained for this method of configuring
    the install process will work.  You have been warned.

2.  Next, run the following commands:

*   perl Makefile.PL   
    Creates AutoDBI.pm.

      During this step you are prompted for several configuration values
      used by Chado and its associated tools:

        *   Use the simple install (uses default database schema) [Y]

        Answering yes skips questions about what exensions to use, and
        eliminates the need to have SQL::Translator installed.  This
        is recomended, and that is all that is necessary in order to use
        the full schema and run GBrowse and gmod-web on top of it.

        *   Use values in '/home/scott/gmod/build.conf'? [Y]

        If `perl Makefile.PL` has been run before, answering yes to this
        will cause Makefile.PL to use the configuration options from the
        previous build.

        *   What database server will you be using? [PostgreSQL] 

        Specify what database vendor to use.  Currently only PostgreSQL works.

        *   What is the Chado database name? [dev_chado_allenday_05] 

        This will be the name of the created chado database.

        *   What is the database username? [allenday] 

        Default user that the installed libraries should try to
        connect to the database as.

        *   What is the password for 'allenday'?  

        Password for the default user.

        *   What is the database host? [localhost] 

        Host of the database daemon.

        *   What is your database port? [5432] 

        Port of the database daemon.

        *   Where shall downloaded ontologies go? [./tmp]

        The directory where ontology files and there lock files will be stored

        *   What is the default organism (common name, or "none")?



        At this point, if you answered "No" to the "use default schema"
        question, you will be prompted about what database exensions
        to use; generally, you should answer "Yes" to that question.
        To see the documentation for this part of the make procedure,
        see "CUSTOM DATABASE SCHEMAS" at the end of this document.

*   make
    Creates necessary files for the rest of the build process.


*   (sudo) make install
    Probably needs to be run as root.  Installs data loading scripts
    in /usr/local/bin, perl modules, as well as placing various files
    in $GMOD_ROOT, and creating the infastructure for logging of
    errors by creating $GMOD_ROOT/logs and creating the
    file /etc/log4perl.conf if it does not already exist.


*   make load_schema
    Creates database, installs schema.  Note that it will wipe out
    any database with the same name in the process!


*   make prepdb
    Inserts a few useful items into fundamental Chado tables. It 
    uses load/etc/initialize.sql.  It contains information for several
    common organisms and source databases (eg, genbank). This file
    can be edited to add any organism or source database, using the
    INSERT statements for the examples as a template.  Note also that
    the prepdb target needs to be executed before the ontologies target,
    but it can be executed again later, if more insert statements are
    added (for instance to add a new organism or database).


*   make ontologies
    Gets and installs various ontologies.  Requires a network 
    connection.  Absolutely required are the Relationship Ontology and
    the Sequence Ontology Feature Annotation (SOFA).  All others are
    optional.  Note retrieved ontology files are stored in the directory
    specified when perl Makefile.PL was run (the default is ./tmp).  In
    order to do a repeat installation, lock files need to be removed to
    allow reinstallation of ontologies.  Those lock files can be removed
    by executing `make rm_locks`.  Alternatively, deleting everything in
    the temporary directory will force the re-downloading of the ontology
    data from their respective sources.  Also note that loading a large
    ontology like the Gene Ontology will take several minutes (perhaps
    as long as an hour).

    Note that since `make ontologies` downloads ontology files from their
    online repositories, this step is prone to failure due to network
    problems.  If you already have desired ontology files locally, you
    can execute a command for each file to load it.  Note again that
    the Relationship Ontology is required before all others, and the
    the Sequence Ontology Feature Annotation (SOFA) is absolutely required
    for proper functioning of the database.  The command to load an
    ontology and its definition file (if it exists) is this:

        $ gmod_load_ontology.pl /path/to/onto_file [/path/to/def_file]

    If you plan on using gmod-web, it might also be a good idea to 
    compute the closures on the ontology relationships.  To do this,
    execute the make_cvtermpath.sh shell script:

        $ bin/make_cvtermpath.sh

    This script takes a very long time to execute, so be prepared to wait,
    or go home for the night.  Also be aware that it will spout many 
    warnings from the database; these can safely be ignored.

    It is not a bad idea at this point to make a back up of the database,
    particularly if you loaded a large ontology like GO.  To make a complete
    dump of the database, issue this command:

        $ pg_dump <database name>  >   <ontologies only sql filename>

    and to restore the database, issue this command:

        $ psql <database name>     <   <ontologies only sql filename>


With that, the installation of the schema is complete.  The easiest way
to load data into the database is to use a GFF3 file and the script
gmod_bulk_load_gff3.pl.  A nice set of sample data is the GFF3 file prepared
by the nice folks at the Saccraromyces Genome Database, at

    ftp://ftp.yeastgenome.org/pub/yeast/data_download/chromosomal_feature/saccharomyces_cerevisiae.gff

This file contains gene ontology (GO) anotations, so if you didn't load
GO when you executed `make ontologies`, you will get many warning messages
about being unable to find entries in the dbxref table.  If you want to
load GO now, you can execute `make ontologies` and select 'Gene Ontology'
for installation.

Then execute gmod_bulk_load_gff3.pl: 

    gmod_bulk_load_gff3.pl --organism yeast \
                           --gfffile saccharomyces_cerevisiae.gff

    (note that the '\' is included to allow cutting and pasting to a unix
    command line.)
    This loads the GFF3 file.  The loading script requires GFF3 as it has
    tighter control of the syntax and requires the use of a controlled
    vocabulary (from Sequence Ontology Feature Annotation (SOFA)), allowing
    mapping to the relational schema.  In addition to supplying the location
    of the file with the --gfffile flag, the --orgainism tag uses the common
    name from the organism table.  See `perldoc gmod_bulk_load_gff.pl` for
    more information on adding other organisms and databases, as well as
    other available commandline flags.

    GFF3 files can also be generated from GenBank entries with a few scripts.
    One is included with this package (but not documented):
    gmod_genbank2gff3.pl script:

        $ gmod_genbank2gff3.pl <genbank file> > <gff file>

    Note that is a redirect of standard out to a GFF file to collect the 
    results of the script.  GFF3 can also be generated via a script provided
    with bioperl, bp_genbank2gff.pl:

        $ bp_genbank2gff.pl --stdout --file <genbank file> > <gff file>

    Again note the redirection of standard out.  Note that neither of
    these methods for generating GFF3 files is completely satisfactory and
    development is ongoing to provide better translation.

DUMPING GFF3

The script gmod_dump_gff3.pl can be used to dump GFF3 from a chado
database.  If executed with no arguments, dump_gff3.pl will dump all
features for the default organism in the database.  Alternatively,
you can provide the organism or reference sequence to dump.

GENERIC GENOME BROWSER

Finally, to browse the data in chado, install the Generic Genome Browser,
GBrowse.  To do this execute the following commands (substituting the
version number for the 'x's):

    $ tar -zxvf Generic-Genome-Browser-x.xx.tar.gz
    $ cd Generic-Genome-Browser-x.xx
    and follow the instruction in the INSTALL documentation.

After installing GBrowse, go to 

  http://localhost/gbrowse/docs/pod/README-chado.html

for more information on configuring GBrowse to work with chado.


CUSTOM DATABASE SCHEMAS

        If you answered "No" to the "use default schema" question,
        you will be prompted about what database exensions
        to use; generally, you should answer "Yes" to that question.
        Here are the questions to answer for this section of the 
        make procedure:

        *   Available extensions to the core schema:
            [1] sequence/gff-bridge/sequence-gff-views.sql
            [2] expression/rad.sql
            [3] expression/expression.sql
    
    
            What extensions to the core schema would you like?
            (Note that selecting any of these will force the
            rebuilding of Class::DBI classes.)
            (Comma-delimited)? [0]
    
            Available function extensions to the core schema:
           [1] sequence/gff-bridge/sequence-gff-funcs.pgsql
           [2] sequence/functions/feature_subalignments.plpgsql
    
        !!!!!IMPORTANT!!!!!
        This section is where you choose optional extensions to the
        base Chado schema.
    
        If you plan to use Chado in combination with GBrowse, make
        sure you select (1) from both menus.
    
        If you plan to store many alignments with small regions of
        perfect match, you might want to load the alignment data
        as an alignment string rather than creating a feature for
        each aligned block.  Functionality exists for using this
        method in (2) of the function extentions, and is documented
        in README.H_sapiens.
    
        If you plan to represent gene expression data in a way that
        is compliant with MIAME standards, make sure you select (2)
        and (3) from the core schema exentions
.
        !!!!!IMPORTANT!!!!!
    
        *   Enter the full path of an external DDL file [none]
    
        Path to a file containing external SQL commands to execute
        after the database has been created.  This will typically be
        extra modules/views/tables not distributed with the core schema,
        or default data to insert into the database to fulfill the
        specialized needs of a MOD.
    

